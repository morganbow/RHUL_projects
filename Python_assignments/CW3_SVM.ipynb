{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing support vector machine algorithms and cross conformal prediction on the wine dataset from sklearn and the USPS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "# ---------------\n",
    "### 1) SVM on the wine dataset\n",
    "### 2) SVM on the USPS dataset\n",
    "### 3) SVM with cross-conformal prediction on the wine dataset\n",
    "### 4) SVM with cross-confromal prediction on the USPS dataset\n",
    "### 5) Results\n",
    "# ---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SVM on the wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, random_state=1504)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set generalization accuracy is: 0.4364265364265364\n",
      "The test error rate is: 0.6222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "#Set gamma = 'auto' to stop a warning message mentioning an update to the SVC class\n",
    "svc = SVC(gamma='auto')\n",
    "scores = cross_val_score(svc, X_train, y_train, cv=5)\n",
    "train_accuracy = sum(scores)/len(scores)\n",
    "print(\"The training set generalization accuracy is:\", train_accuracy)\n",
    "svc.fit(X_train, y_train)\n",
    "test_error_rate = sum(np.argmax(svc.decision_function(X_test), axis=1)!=y_test)/len(X_test)\n",
    "print(\"The test error rate is:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the gamma and C paramters not being tuned and the data not being normalized we see a low accuracy for the training data and a high error rate on the test data. Both the high error rate and low generlalization accuracy indicate show that our resukts can be greatly improved upon. This will be done by normalising the data and cgoosing the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next I found the best normalizer for the data and also the best parameters for that normalizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler test error rate and best paramters: (0.022222222222222254, {'svc__C': 1, 'svc__gamma': 1})\n",
      "StandardScaler test error rate and best paramters: (0.022222222222222254, {'svc__C': 1, 'svc__gamma': 0.01})\n",
      "RobustScaler test error rate and best paramters: (0.022222222222222254, {'svc__C': 1, 'svc__gamma': 0.1})\n",
      "Normalizer test error rate and best paramters: (0.0444444444444444, {'svc__C': 100, 'svc__gamma': 100})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid ={'svc__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "min_max_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "robust_scaler = RobustScaler()\n",
    "normalizer = Normalizer()\n",
    "scalers = (min_max_scaler, standard_scaler, robust_scaler, normalizer)\n",
    "scores = {}\n",
    "for scaler in scalers:\n",
    "    pipe = make_pipeline(scaler, SVC())\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, iid='True')\n",
    "    grid.fit(X_train, y_train)\n",
    "    a = str(scaler).split(\"(\")\n",
    "    a = str(a[0])\n",
    "    scores[a] = (1 - grid.score(X_test,y_test), grid.best_params_)\n",
    "print(\"MinMaxScaler test error rate and best paramters:\", scores['MinMaxScaler'])\n",
    "print(\"StandardScaler test error rate and best paramters:\", scores['StandardScaler'])\n",
    "print(\"RobustScaler test error rate and best paramters:\", scores['RobustScaler'])\n",
    "print(\"Normalizer test error rate and best paramters:\", scores['Normalizer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reults show that MinMaxScaler, StandardScaler and RobustScaler all perform equally well but all use slightly different values for the parameters C and gamma.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-normalized data test error rate and best parameters (0.1777777777777778, {'C': 100, 'gamma': 0.001})\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "param_grid ={'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(svc, param_grid=param_grid, cv=5, iid='True')\n",
    "grid.fit(X_train, y_train)\n",
    "scores = (1- grid.score(X_test,y_test), grid.best_params_)\n",
    "print(\"Non-normalized data test error rate and best parameters\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the test error rate if the GridSearch was used to find the best parameters but the data was not normalized. The error rate is a clear improvement on the initial error rate that was obtained before we tuned the parameters or normalized the data. On the other hand, it is also a much worse error rate then the results obtained when we normalized the data and found the best parameters. This highlights the importance of both normalization and parameter selection in creating the best model for the wine dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SVM on the USPS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X1 = np.genfromtxt(\"digit_test.txt\", delimiter=\" \", usecols=np.arange(256)+1)\n",
    "X2 = np.genfromtxt(\"digit_train.txt\", delimiter=\" \", usecols=np.arange(256)+1)\n",
    "y1 = np.genfromtxt(\"digit_test.txt\", delimiter=\" \", usecols=0)\n",
    "y2 = np.genfromtxt(\"digit_train.txt\", delimiter=\" \", usecols=0)\n",
    "X = np.concatenate((X1,X2))\n",
    "y = np.concatenate((y1,y2))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1504)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set generalization accuracy is: 0.9685931597850266\n",
      "The test error rate is: 0.03483870967741935\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(gamma='auto')\n",
    "scores = cross_val_score(svc, X_train, y_train, cv=5)\n",
    "train_accuracy = sum(scores)/len(scores)\n",
    "print(\"The training set generalization accuracy is:\", train_accuracy)\n",
    "svc.fit(X_train, y_train)\n",
    "test_error_rate = (sum(svc.predict(X_test)!=y_test))/len(X_test)\n",
    "print(\"The test error rate is:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set generalization accuracy and test error rate imply that the model gives accurate results even before gamma and C have been tuned and the data has been normalized. It is clear to see actually from looking at the first observation from the data, shown below, that normalization of the data will not improve the results as all of the features are already in a range from [-1,1]. I will still normalize the data with all the scaler options to comfirm this hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.   , -1.   , -1.   , -1.   , -1.   , -0.948, -0.561,  0.148,\n",
       "        0.384,  0.904,  0.29 , -0.782, -1.   , -1.   , -1.   , -1.   ,\n",
       "       -1.   , -1.   , -1.   , -1.   , -0.748,  0.588,  1.   ,  1.   ,\n",
       "        0.991,  0.915,  1.   ,  0.931, -0.476, -1.   , -1.   , -1.   ,\n",
       "       -1.   , -1.   , -1.   , -0.787,  0.794,  1.   ,  0.727, -0.178,\n",
       "       -0.693, -0.786, -0.624,  0.834,  0.756, -0.822, -1.   , -1.   ,\n",
       "       -1.   , -1.   , -0.922,  0.81 ,  1.   ,  0.01 , -0.928, -1.   ,\n",
       "       -1.   , -1.   , -1.   , -0.39 ,  1.   ,  0.271, -1.   , -1.   ,\n",
       "       -1.   , -1.   ,  0.012,  1.   ,  0.248, -1.   , -1.   , -1.   ,\n",
       "       -1.   , -1.   , -0.402,  0.326,  1.   ,  0.801, -0.998, -1.   ,\n",
       "       -1.   , -0.981,  0.645,  1.   , -0.687, -1.   , -1.   , -1.   ,\n",
       "       -1.   , -0.792,  0.976,  1.   ,  1.   ,  0.413, -0.976, -1.   ,\n",
       "       -1.   , -0.993,  0.834,  0.897, -0.951, -1.   , -1.   , -1.   ,\n",
       "       -0.831,  0.14 ,  1.   ,  1.   ,  0.302, -0.889, -1.   , -1.   ,\n",
       "       -1.   , -1.   ,  0.356,  0.794, -0.836, -1.   , -0.445,  0.074,\n",
       "        0.833,  1.   ,  1.   ,  0.696, -0.881, -1.   , -1.   , -1.   ,\n",
       "       -1.   , -1.   , -0.368,  0.955,  1.   ,  1.   ,  1.   ,  1.   ,\n",
       "        0.905,  1.   ,  1.   , -0.262, -1.   , -1.   , -1.   , -1.   ,\n",
       "       -1.   , -1.   , -1.   , -0.507,  0.451,  0.692,  0.692, -0.007,\n",
       "       -0.237,  1.   ,  0.882, -0.795, -1.   , -1.   , -1.   , -1.   ,\n",
       "       -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   ,\n",
       "        0.155,  1.   ,  0.436, -1.   , -1.   , -1.   , -1.   , -1.   ,\n",
       "       -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -0.991,\n",
       "        0.703,  1.   , -0.025, -1.   , -1.   , -1.   , -1.   , -1.   ,\n",
       "       -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -0.833,\n",
       "        0.959,  1.   , -0.629, -1.   , -1.   , -1.   , -1.   , -1.   ,\n",
       "       -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -0.6  ,\n",
       "        0.998,  0.841, -0.932, -1.   , -1.   , -1.   , -1.   , -1.   ,\n",
       "       -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -0.424,\n",
       "        1.   ,  0.732, -1.   , -1.   , -1.   , -1.   , -1.   , -1.   ,\n",
       "       -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -0.908,\n",
       "        0.43 ,  0.622, -0.973, -1.   , -1.   , -1.   , -1.   , -1.   ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler test error rate and best paramters: (0.029247311827957034, {'svc__C': 100, 'svc__gamma': 0.01})\n",
      "StandardScaler test error rate and best paramters: (0.03139784946236557, {'svc__C': 10, 'svc__gamma': 0.001})\n",
      "RobustScaler test error rate and best paramters: (0.12301075268817208, {'svc__C': 100, 'svc__gamma': 0.001})\n",
      "Normalizer test error rate and best paramters: (0.027956989247311825, {'svc__C': 10, 'svc__gamma': 1})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid ={'svc__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "min_max_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "robust_scaler = RobustScaler()\n",
    "normalizer = Normalizer()\n",
    "scalers = (min_max_scaler, standard_scaler, robust_scaler, normalizer)\n",
    "scores = {}\n",
    "for scaler in scalers:\n",
    "    pipe = make_pipeline(scaler, SVC())\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, iid='True', n_jobs = -1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    a = str(scaler).split(\"(\")\n",
    "    a = str(a[0])\n",
    "    scores[a] = (1 - grid.score(X_test,y_test), grid.best_params_)\n",
    "print(\"MinMaxScaler test error rate and best paramters:\", scores['MinMaxScaler'])\n",
    "print(\"StandardScaler test error rate and best paramters:\", scores['StandardScaler'])\n",
    "print(\"RobustScaler test error rate and best paramters:\", scores['RobustScaler'])\n",
    "print(\"Normalizer test error rate and best paramters:\", scores['Normalizer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the Normalizer scaler gives the lowest test error rate. Now I will find the best parameters without normalizing the data to see if my hypothesis that normalizing the data is unnecessary is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-normalized data test error rate and best parameters (0.026236559139784954, {'C': 10, 'gamma': 0.01})\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "param_grid ={'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(svc, param_grid=param_grid, cv=5, iid='True', n_jobs = -1)\n",
    "grid.fit(X_train, y_train)\n",
    "scores = (1 - grid.score(X_test,y_test), grid.best_params_)\n",
    "print(\"Non-normalized data test error rate and best parameters\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error rate when the data is not normalized but the best paramters are used is lower than the one found when we normalised the data. This confirms that there is no need to normalize the USPS dataset as it doesn't improve the accuarcy and it reduces the computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SVM with cross-confromal prediction on the wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, random_state=1504)\n",
    "svc = SVC(C=1, gamma=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I have implemented a cross-conformal prediction using 3 folds, 5 folds and 10 folds. I have used the MinMaxScaler as it was one of the scalers that gave the best test error rate in the GridSearch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average false p value for 3 fold cross-confromal prediction is: 0.009690893901420224\n",
      "The average false p value for 5 fold cross-confromal prediction is: 0.011959287531806629\n",
      "The average false p value for 10 fold cross-confromal prediction is: 0.008651399491094159\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "folds = [3,5,10]\n",
    "average_false_p_value = np.empty(0)\n",
    "param_grid ={'svc__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "for f in range(len(folds)):\n",
    "    kf = KFold(shuffle=True, random_state=1504, n_splits=folds[f])\n",
    "    alpha = np.empty(0)\n",
    "    for rest_index, fold_index in kf.split(X_train):\n",
    "        X_rest, X_fold, y_rest, y_fold = X_train[rest_index], X_train[fold_index], y_train[rest_index], y_train[fold_index]\n",
    "        pipe = make_pipeline(MinMaxScaler(), SVC())\n",
    "        grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, iid='True', n_jobs = -1)\n",
    "        grid.fit(X_rest, y_rest)\n",
    "        all_calibration_conformity_scores = grid.decision_function((X_fold))\n",
    "        calibration_conformity_scores = np.empty(len(all_calibration_conformity_scores))\n",
    "        for i in range(len(all_calibration_conformity_scores)):\n",
    "            calibration_conformity_scores[i] = all_calibration_conformity_scores[i,y_fold[i]]\n",
    "        X_test_conformity_scores = grid.decision_function(X_test)\n",
    "        for i in range(len(X_test)):\n",
    "            for j in range(3):\n",
    "                rank = 0\n",
    "                for k in range(len(X_fold)):\n",
    "                    if X_test_conformity_scores[i,j] >= calibration_conformity_scores[k]:\n",
    "                        rank += 1\n",
    "                alpha = np.append(alpha,rank)\n",
    "\n",
    "    alpha = alpha.reshape(folds[f],len(X_test),3) \n",
    "    p_values = (sum(alpha)+1)/((len(X_fold)*folds[f])+1)\n",
    "    false_p_value = 0\n",
    "    for a in range (len(p_values)):\n",
    "        false_p_value += np.sum(p_values[a]) - p_values[a,y_test[a]]\n",
    "    average_false_p_value = np.append(average_false_p_value, (false_p_value/(p_values.shape[0]*(p_values.shape[1]-1))))\n",
    "print(\"The average false p value for 3 fold cross-confromal prediction is:\", average_false_p_value[0])\n",
    "print(\"The average false p value for 5 fold cross-confromal prediction is:\", average_false_p_value[1])\n",
    "print(\"The average false p value for 10 fold cross-confromal prediction is:\", average_false_p_value[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest average false p value occurs when we used 10 folds. As the wine dataset is quite small using more folds doesn't greatly reduce the computatinal efficiency but it will start to reduce the size of the calibration sets. Having a larger number of folds will reduce the size even more and risk affecting the validity of the results. 10 folds seems to be the optimal folds for the wine dataset cross-confromal prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZgU1dXH8e8BBFFxieAGDBiDRjTGhaBEjXkV10TQN0pAUVEjbuhjRCORxF3jbiSSICoRIqBIlCDBLVFRjCC4oaK+EoIBCQERcUGWYc77xy20aWama4aprumu3+d5+pnurjtV5/b09Om6t+695u6IiEh2NUk7ABERSZcSgYhIxikRiIhknBKBiEjGKRGIiGScEoGISMYpEWSUmbmZfSu6P8zMfh3d/6GZLUj42Ceb2VNJHqMxMbPtzex5M/vMzG4r4nEvN7N7i3Ssr95PUnqapR2A1J+ZnQRcDHwb+Ax4Hbje3afWZT/ufk4C4QFgZh2BfwGbuHtldLzRwOikjtkI9Qc+Arb0Ig7ccfcbinWsuKp7P5TyccqFzghKlJldDPwWuAHYHqgAfg/0LHIcTYt5vGIws4b+gtQBmF2fJJBALCIbcnfdSuwGbAV8DpxYS5muwEvAJ8B/gLuA5jnbHfhWdP9+4Lro/g+BBcDlhG+x84CTc37vfuAPwGTgC6A78CPgNeBTYD5wVU75f0fH+jy6dQP6AVNzynwfmAEsj35+P2fbc8C1wIuEs56ngNa11Lsn4czoU+CfwFHR8/OA7jnlrgIeiO53jGI8M4r3eeAJYEDevt8A/je6/23gaeBj4D2gVw3x3A+sAVZH9e8OtCAk8YXR7bdAi7zX/zJgEfCnavb5AbBfdL9vFHvn6PHPgAm11PG0qI4fAYNz9tkEGBS9ZkuBccA3anmdLyW8rxYCZ7D++6mu74ddgGei435EOFvcOud3LgM+jP7+7wGHFYq5uuOk/X/bmG+pB6BbPf5ocBRQCTSrpcx+wAGE5r+OwDvARTnba0sElcDt0QfWIYQP/N1yyi4HDoz+ETeNfuc70eO9gP8Cx0Xl130ANcs5dj+iRAB8A1gGnBLF2id6vG20/bnoH31XoGX0+MYa6tw1iu3wKJa2wLejbfMonAhGAZtHxzkVeDGnfGdCUm0RlZkPnB7FvG/0AbZHDXF99fpGj68BpgHbAW2AfwDX5r3+N0XHalnN/kYBA6P7w6PX59ycbT+vpY73RPX7LrAK2D3aflEUU7vouHcDY2t5//0X2DN6Lcaw/vupru+Hb0V/sxbR6/E88Nto227Ra71Tzu/vUijm6o6jW803NQ2Vpm2Bj7yWtk93f8Xdp7l7pbvPI/yTHFKHY/za3Ve5+xTgr0CvnG1/cfcX3b3K3Ve6+3Pu/mb0eBYwtg7H+hHwvrv/KYp1LPAucGxOmT+6+/+5+5eEb31717CvM4ER7v50FMuH7v5uHep8lbt/ER3nUWBvM+sQbTsZeMTdVwE/Bua5+x+jmF8F/gycEPM4JwPXuPtid18CXE1IhOtUAVdGr/+X1fz+FL5+fQ8GfpPz+JBoe02udvcv3f0NwhnOd6PnzyacISyI6ngVcEINTVO9CH+Tt9z9i6jsV+r6fnD3OdHfbFX0etyeU34t4UO+s5lt4u7z3P2f9YhZaqFEUJqWAq1re8Ob2a5mNsnMFpnZp4S+hNYx978s+gdf5wNgp5zH8/OOtb+ZPWtmS8xsOXBOHY61U7T/XB8Qvs2vsyjn/gpgixr21Z7w7bi+vqqXu39GSIC9o6d683UHdwdgfzP7ZN2N8OG+Q8zj5Nc5//Vd4u4ra/n9KcDBZrYD0BR4CDgw6iDditA0VpOaXssOwKM59XmH8CG8fQ3x574H1vv71fX9YGbbmdmDZvZh9F59YF15d59D+OZ/FbA4KrfutapLzFILJYLS9BKwEjiuljJ/IHyz7uTuWxLa/C3m/rcxs81zHlcQ2oLXye/0HANMBNq7+1bAsJxjFeogXUj4h85VQWgTrqv5hPbm6nwBbJbzuLoP7fxYxwJ9zKwboTnl2ZzjTHH3rXNuW7j7uTHjzK9zodd3/SDDh+MK4ELg+ShpLSJcnTTV3atixpFrPnB0Xp02dffq/g7/ISTd3Phz1fX98Jvo+b2i92rfnPK4+xh3P4jwmjmh2axQzJpWuQ6UCEqQuy8HrgCGmtlxZraZmW1iZkeb2c1RsVaEzrrPzezbQNwPqXWuNrPmZnYwoSnk4VrKtgI+dveVZtYVOCln2xJCU8c3a/jdycCuZnaSmTUzs58S2uMn1TFegPuA083sMDNrYmZto7pD+JbcO3qduhCvGWcy4cPnGuChnA/YSVHMp0T728TMvmdmu8eMcyzwKzNrY2atCX/LB+JWMjIFGMDXzUDP5T2uq2HA9euawqLYaroCbRzQz8w6m9lmwJV52+v6fmhF6ND9xMzaEjqiieLYzcwONbMWhC8/XxK+9ReKudD7TnIoEZQod7+dMIbgV4Q3/XzCB8GEqMglhH/AzwgdhA/VYfeLCB22CwnNIecUaGs/D7jGzD4jfKiNy4lzBXA98GJ0Cn9AXj2WEhLNQEKT1y+AH7v7R3WId92+XiZ04N5B6DSewtffvH9NOFtYRmiTHxNjf6uARwhX+ozJef4z4AhCc9FCwuu1rnM3juuAmcAs4E3g1ei5uphC+AB9vobHdXUn4Vv8U9HfcRqwf3UF3f1xwpVOzwBzop+56vp+uJrQ4b6c0Bz3SM6+WgA3EjrjFxE62C8vFHOh952sz9x1BiUikmU6IxARyTglAhGRjFMiEBHJOCUCEZGMK7kReK1bt/aOHTumHYaISEl55ZVXPnL3NtVtK7lE0LFjR2bOnJl2GCIiJcXM8kfwf0VNQyIiGadEICKScUoEIiIZp0QgIpJxSgQiIhmXWCIwsxFmttjM3qphu5nZEDObY2azzGzfpGIREZGaJXlGcD9hSbuaHA10im79CfPni4hIkSU2jsDdn49WTKpJT2CUh+lPp5nZ1ma2o7v/J6mYREQatRUr4O67Ydmy6rcfeyx873sNftg0B5S1Zf3l7hZEz22QCMysP+GsgYqK/MWQRETKxMCBMGwYWA2LCe60UyKJIM3O4upqWu3iCO4+3N27uHuXNm2qHSEtIlLa/vrXkAQuuQSqqqq/nXNOIodOMxEsYP11T9ux/rqtIiLZsHgxnHEG7LUXXFfXxeo2XppNQxOBAWb2IGF5ueXqHxCRzFi8GFatCvcHDIBPPoG//Q1axF3xtOEklgjMbCzwQ6C1mS0gLHC9CYC7DyMsDH4MYc3TFYS1ZkVEyt8dd8DFF6//3O23w3e+k0o4SV411KfAdgfOT+r4IiKN0muvwWWXwZFHwoknhufatIEf/zi1kEpuGmoRkZL15ZfQty+0bg2jR8O226YdEaBEICJSPIMGwezZ8OSTjSYJgOYaEhEpjqefhiFD4IIL4Igj0o5mPUoEIiJJ+/hj6NcPdt8dbrop7Wg2oKYhEZEkuYeBYEuWwGOPQcuWaUe0ASUCEZEkPfAAPPww/OY3sG/jnGRZTUMiIkn54IMwWOzgg+HSS9OOpkZKBCIiSbn1VlizBkaNgqZN046mRkoEIiJJeeEFOOgg6Ngx7UhqpUQgIpKE5cth1qyQCBo5JQIRkSS89FK4YujAA9OOpCAlAhGRJEydGvoF9t8/7UgKUiIQEUnCiy/CPvvAFlukHUlBSgQiIg1t9WqYPr0kmoVAiUBEpOG99lqYabQEOopBiUBEpOFNnRp+6oxARCSjXnwRdtkFdtwx7UhiUSIQEWlI7uGMoETOBkCJQESkYb3/fphptET6B0Czj4qIxPfllzB/fu1lJkwIP5UIRETKzPLlsN9+8M9/Fi7bpg3stlvyMTUQJQIRkTgGDIB58+Cuu2CbbWov27kzNCmdlnclAhGRQsaNCwvMXHklnH9+2tE0uNJJWSIiaViwICw12bUrDB6cdjSJUCIQEalJVRWcfjqsWhXOCDbZJO2IEqGmIRGRmgwZAn/7G9x9N3TqlHY0idEZgYhIdd56CwYNgh//GM46K+1oEqVEICKSb9Uq6NsXttwS7r0XzNKOKFFqGhKR7KiqgieegKVLay/3zDPwxhswcSJsv31xYkuREoGIZMdtt8EvfhGv7HnnwbHHJhtPI6FEICLZ8MYb4fLP446DW2+tvWzTptChQ3HiagQSTQRmdhRwJ9AUuNfdb8zbXgGMBLaOygxy98lJxiQiGbRyJZx8Mmy7LdxzD7RunXZEjUpiicDMmgJDgcOBBcAMM5vo7rNziv0KGOfufzCzzsBkoGNSMYlIRv3yl/D22/D440oC1UjyjKArMMfd5wKY2YNATyA3ETiwZXR/K2BhgvGISLkZMiRc4rl2be3lVq8OU0McdVRx4ioxSSaCtkDufK0LgP3zylwFPGVmFwCbA92r25GZ9Qf6A1RUVDR4oCJSgmbOhIEDwwIw3brVXnbbbctyjqCGkmQiqO7CW8973Ae4391vM7NuwJ/MbE93r1rvl9yHA8MBunTpkr8PEcmaFSvCdf477ACPPlp4NlCpVZKJYAHQPudxOzZs+jkTOArA3V8ys02B1sDiBOMSkVJ36aXw3nth+gclgY2WZCKYAXQys52BD4HewEl5Zf4NHAbcb2a7A5sCSxKMSURK0fPPh6mgIZwN/PGP8POfw2GHpRtXmUgsEbh7pZkNAJ4kXBo6wt3fNrNrgJnuPhEYCNxjZj8nNBv1c3c1/YjI+i64AN59F1q1Co+POAJuuCHdmMpIouMIojEBk/OeuyLn/mzgwCRjEJES99ZbMGtWuELoggvSjqYsadI5EWncxo4Nyz726pV2JGVLiUBEGi/3kAi6d8/E5G9pUSIQkcZr+nT417+gT5+0IylrSgQi0niNHQstWsDxx6cdSVlTIhCRxqmyEh56KKwQttVWaUdT1pQIRKRxeu45+O9/4aT84UfS0LQegYgU15o1cM454ZLQ2ixcGJaKPOaY4sSVYUoEIlJc118PI0aEUcEtWtRcbrvtoEcP2HTT4sWWUUoEIlI806bBddfBKafAqFFpRyMR9RGISHF8/nmYMbRdO/jd79KORnLojEBEGk5VFUyYAEuqmTvyySdh7lyYMkVXATUySgQi0nDuuAMuuaTm7VdcAQcfXLx4JBYlAhFpGLNmweWXw3HHwe9/v+H2Zs2gTZvixyUFKRGIyMZbuRJOPjksEjN8uD7wS4wSgYjEV1VV/fODB4fpoidPVhIoQUoEIhLPqFFw1lmwenX12887D44+urgxSYNQIhCRwt5/H849F/bZp/qRvltvHZKElCQlAhGpXWVlGADWogWMHx/GAUhZUSIQkdpdf31YF+Chh5QEypQSgYisb+ZMGDYsdAyvXQujR4cRwVoqsmwpEYjI1z76CI49NkwHsc024bmDD4a77ko3LkmUEoGIBO5w9tmwdCm8/DLsvXfaEUmRKBGISDByJDzyCNx0k5JAxmj2UREJC8RfeCH84AcwcGDa0UiRKRGIZN3atXDqqWAWBo01bZp2RFJkBROBmW1vZveZ2ePR485mdmbyoYlIUdx8M0ydGjqEO3RIOxpJQZwzgvuBJ4Gdosf/B1yUVEAiUkSvvhqmhu7VK1wiKpkUJxG0dvdxQBWAu1cCaxONSkSSt2JFmDF0++3hD38ITUOSSXGuGvrCzLYFHMDMDgCWJxqViCTvqqvg3Xfh6afhG99IOxpJUZxEcDEwEdjFzF4E2gAnJhqViCRr9Wq4997QJNS9e9rRSMriNA29DRwCfB84G9gDeDfOzs3sKDN7z8zmmNmgGsr0MrPZZva2mY2JG7iIbISnnoJly8LVQpJ5cc4IXnL3fQkJAQAzexXYt7ZfMrOmwFDgcGABMMPMJrr77JwynYBfAge6+zIz264edRCRuhozJjQHHX542pFII1BjIjCzHYC2QEsz2wdY15O0JbBZjH13Bea4+9xofw8CPYHZOWXOAoa6+zIAd19c5xqISN188QX85S9haunmzdOORhqB2s4IjgT6Ae2A23Oe/wy4PMa+2wLzcx4vAPbPK7MrQNT30BS4yt2fyN+RmfUH+gNUVFTEOLSI1GjixHDFUJ8+aUcijUSNicDdRwIjzewn7v7neuy7umvRvJrjdwJ+SEg4L5jZnu7+SV4sw4HhAF26dMnfh4jUxZgx0LZtmFVUhBh9BO7+ZzP7EaGTeNOc568p8KsLgPY5j9sBC6spM83d1wD/MrP3CIlhRozYRaSuli6FJ56Aiy6CJpphRoKCicDMhhH6BP4HuBc4AXg5xr5nAJ3MbGfgQ6A3cFJemQlAH+B+M2tNaCqaGzt6kSxas6bmBeQLefDBsPSkmoUkR5yrhr7v7nuZ2Sx3v9rMbgMeKfRL7l5pZgMI01M0BUa4+9tmdg0w090nRtuOMLPZhNHKl7r70vpXR6TMvfYaHHoofPJJ4bI12XXXsAi9SCROIlgZ/VxhZjsBS4Gd4+zc3ScDk/OeuyLnvhMGrF0cK1qRLPvyyzAlxGabweVxrteowaGHajoJWU+cRPCYmW0N3AK8SujwvSfRqERkQ4MGwTvvhMFguv5fGlCticDMmgB/j67i+bOZTQI2dXfNNSRSTE89BUOGhMVjlASkgdWaCNy9KuoT6BY9XgWsKkZgIpm2eDFcdhmsjFpmn3kGOneGG29MNy4pS3Gahp4ys58Aj0Rt+iKStHvugfvvDx27ABUVYZK4li1TDUvKU9zZRzcHKs1sJWGgmLv7lolGJpJV7mHQ10EHwQsvpB2NZECcAWWtihGIiETefBNmz4ahQ9OORDJCQwtFGpuxY8MC8idq2Q8pDiUCkcakqiokgsMPhzZt0o5GMkKJQKQxeekl+OADOCl/NhaR5NSaCMysiZm9VaxgRDJv7FjYdFM47ri0I5EMqTURuHsV8IaZaREAkaRVVsK4cXDssdBK12hI8cS5fHRH4G0zexn4Yt2T7t4jsahEsuixx2DJEjULSdHFSQRXJx6FSNZ9/DEMGAC77w5HH512NJIxccYRTDGz7YHvRU+9rLWFRRqQO5x9djgbmDQJWrRIOyLJmIJXDZlZL8JCNCcCvYDpZnZC0oGJZMaf/gTjx8M112idAElFnKahwcD31p0FmFkb4G/A+CQDEykrc+eGjuD86bqqquCmm8L6wZdemk5sknlxEkGTvKagpWj8gUh8n30WBojNrWEV1p12glGjwmhikRTESQRPmNmTwNjo8U/JW3VMRGpx0UUwbx489xwccMCG25s1UxKQVMXpLL7UzP4XOIgw8+hwd3808chEysEjj8CIEWFpyUMOSTsakWoVWqGsKfCku3cnxoL1ImVt1Sr49NP45T/+GPr3h/32gyuvTC4ukY1UaIWytWa2wsy20vKUkmmLFkHXrjB/ft1+r2VLeOABaN48mbhEGkCcPoKVwJtm9jTrjyy+MLGoRBoTdzjjjHCd/+231+1D/YAD4NvfTi42kQYQJxH8NbqJZNOwYfD44/C734XRvyJlJk4fweHu3rdI8Yg0Lu+9BwMHwpFHwvnnpx2NSCIKzT66FmhjZmrglOxZswZOOSW0848YAWZpRySSiDhNQ/OAF81sIuv3EdyeVFAijcK118KMGWH6h512SjsakcTESQQLo1sTQJOkSzb84x9w/fXQrx/85CdpRyOSqDgDyq4GMLPN3f2LQuVFSt5nn4UmoYoKuPPOtKMRSVzBRGBm3YD7gC2ACjP7LnC2u5+XdHAiDaqqCqZMgS8KfJ8ZPTpMCTFlCmy5ZVFCE0lTnKah3wJHAhMB3P0NM/tBolGJJOGXv4Sbb45XdvBgOOigZOMRaSTiJALcfb6tf8XE2mTCEUnIlClwyy1w2mmFxwJsuinssUdx4hJpBOIkgvlm9n3Ao8tILwTeibNzMzsKuBNoCtzr7jfWUO4E4GHCugczY0UuEtfy5XDqqbDLLnDXXbDFFmlHJNKoxEkE5xA+zNsCC4CngIIja6LBaEOBw6Pfm2FmE919dl65VoTkMr1uoYvEdMEF8OGHMHWqkoBINeJcNfQRcHI99t0VmOPucwHM7EGgJzA7r9y1wM3AJfU4hsiGRo+GQYOgsjLME/Tf/4bZP6tbC0BE4vUR1FNbIHeqxgXA/rkFzGwfoL27TzKzGhOBmfUH+gNUVFQkEKqUjffeg7POgt12C7OFArRvD5ddlm5cIo1YkomguvH4Xy3YamZNgDuAfoV25O7DgeEAXbp08QLFJavWrIG+fcOUEH/9q0YDi8SUZCJYALTPedyOMEJ5nVbAnsBz0RVJOwATzayHOoylXq69FmbOhIcfVhIQqYPYicDMDgBuAFoAt7j7hAK/MgPoZGY7Ax8CvYGT1m2MFrppnbP/54BLlARkA3//e1jvtzYrV4a1Ak49FU44oShhiZSLGhOBme3g7otynroY6EFo8vkHUGsicPdKMxsAPEm4fHSEu79tZtcAM9194kZHL+WvshJOPjl0+DapdbJc+O53YciQ4sQlUkZqOyMYZmavEL79rwQ+IXyjrwJiLdzq7pOByXnPXVFD2R/G2adkzLPPhiQwfrwmfxNJSI1fsdz9OOB1YJKZnQJcREgCmwHHFSc8ybyxY8N8P8cck3YkImWr0MI0jxHmGdoaeAR4z92HuPuSYgQnGbdyJfz5z3D88eFKIBFJRI2JwMx6mNlU4BngLUJn7/FmNtbMdilWgJJhjz8On34KJ51UuKyI1FttfQTXAd2AlsBkd+8KXGxmnYDrCYlBJDljxsB228Ghh6YdiUhZqy0RLCd82LcEFq970t3fR0lAkvbpp/DYY2GUcLMkh7uISG19BMcTOoYrybn+X6QoJkyAVaugT5+0IxEpezV+1Yomm/tdEWORLKuqgssvh9deC49nz4aOHaFbt1TDEskCnXNL43DXXXDTTbD33mFhmHbt4NxzwaqbskpEGpISgaRv9uwwO+iPfhT6BfThL1JUBcbsiyRs9eowhUSrVnDffUoCIinQGYGk64or4PXX4S9/ge23TzsakUzSGYGkZ9EiuPVWOP106NEj7WhEMkuJQNIzbhysXQuXaJVSkTQpEUh6xo4NU0d37px2JCKZpkQg6Zg7F6ZN04AxkUZAiUDS8eCD4WdvzVYikjYlAik+dxg9Gg48EDp0SDsakcxTIpDie/PNMIhM00uLNApKBFJ8Y8dC06Zw4olpRyIiaECZFMPq1XDnnWHtYQjNQocfDm3apBuXiABKBFIMV14JN94Im28eHjdrBuedl25MIvIVJQJJ1gsvhFlFf/YzuOeetKMRkWqoj0CS8+mncMop8M1vwh13pB2NiNRAZwSSnAsvhPnzYepU2GKLtKMRkRrojECSMX48jBwJgwdrlTGRRk6JQBrewoVw9tnQpQv8+tdpRyMiBSgRSMOqqgrTSn/5JTzwAGyySdoRiUgB6iOQhjV0KDz1FPz+97DbbmlHIyIxKBFI3U2dGsYGrF694bYZM+CYY+Ccc4ofl4jUixKB1M1HH4WpIcxg99033N6zJwwZorWHRUpIoonAzI4C7gSaAve6+4152y8GfgZUAkuAM9z9gyRjko3gHjqBP/4YXn45LCojIiUvsc5iM2sKDAWOBjoDfcwsfymq14Au7r4XMB64Oal4pAGMHAmPPALXXackIFJGkjwj6ArMcfe5AGb2INATmL2ugLs/m1N+GtA3wXikrpYsgSeeCGcCq1fDxRfDIYeEnyJSNpJMBG2B+TmPFwD711L+TODx6jaYWX+gP0BFRUVDxSe1WbkSDjssrB2wTuvW4aygadP04hKRBpdkIqiut9CrLWjWF+gCHFLddncfDgwH6NKlS7X7kAb2q1+FJDB2LHTtGp5r0wZatUo3LhFpcEkmggVA+5zH7YCF+YXMrDswGDjE3VclGI/E9cwzcNttcO65WlNYJAOSHFk8A+hkZjubWXOgNzAxt4CZ7QPcDfRw98UJxiJxLVsGp50WBoPdemva0YhIESSWCNy9EhgAPAm8A4xz97fN7Boz6xEVuwXYAnjYzF43s4k17E6S4h7WDm7ePNzatIFFi8L0EJttlnZ0IlIEiY4jcPfJwOS8567Iud89yeNLDEOHhn6AU06Bdu3Ccz/4QZgwTkQyQSOLs+ydd+DSS8OUECNHajSwSEZp9tGsWr0a+vYNC8bcd5+SgEiG6YwgS0aNgunTw/25c+HVV+HRR2GHHdKNS0RSpUSQFZMmhauBttrq6zUCBg2C445LNy4RSZ0SQRYsXgxnnhnmB5o+HVq0SDsiEWlElAjKnTv87GewfHkYKKYkICJ5lAjK3b33wmOPwR13wB57pB2NiDRCumqonL3/Pvz859C9O1x4YdrRiEgjpURQriorwyCx5s3h/vuhif7UIlI9NQ2Vq+uvDx3DDz0EbdumHY2INGL6mliOpk+Ha68NA8Z69Uo7GhFp5HRGUAy33w5jxhTvePPmhbOAu+4q3jFFpGQpESTt6adh4EDYd1/YccfiHLN9exg8OAweExEpQIkgSUuXQr9+0LkzTJ0KLVumHZGIyAaUCJLiDuecExaAnzRJSUBEGi0lgoY0bRq8/nq4P3cujB8PN9wA++yTblwiIrVQImgoq1bB0UfDJ598/Vz37vCLX6QXk4hIDEoEDeXxx0MSGDcODj44PLfddhrIJSKNnhJBQxkzJqz3e/zx0Ewvq4iUDn1dbQiffRYmduvVS0lAREqOEkFDmDABVq6EPn3SjkREpM6UCBrCmDHQoQN065Z2JCIidaZEsLGWLAmjh3v3VsewiJQkfXJtrIcfhrVr4aST0o5ERKRelAg2hjuMHh1W/vrOd9KORkSkXpQINsYDD8A//gFnnQVmaUcjIlIvSgT1NW8eDBgABx0UfoqIlCglgvpYuxZOPTU0DY0aBU2bph2RiEi9afRTbd5/P1wVlG/SJHjhhbAW8M47Fz0sEZGGpERQkwkTwnQRNfnJT8JZgYhIiVMiqM6iRaEDeN994Te/2XB7s2ZhYjl1EItIGUg0EZjZUcCdQFPgXne/MW97C2AUsB+wFPipu89LMqaC3OGMM+Dzz8NVQbvvnmo4IiJJS6yz2MyaAkOBo4HOQB8z65xX7Exgmbt/C7gDuCmpeGIbNko5kjsAAAbXSURBVCxMKX3LLUoCIpIJSZ4RdAXmuPtcADN7EOgJzM4p0xO4Kro/HrjLzMzdvcGjGTECbrutcLk5c+DII+H88xs8BBGRxijJRNAWmJ/zeAGwf01l3L3SzJYD2wIf5RYys/5Af4CKior6RbPttmER+UK6dYPrrlP7v4hkRpKJoLpP0vxv+nHK4O7DgeEAXbp0qd/ZQs+e4SYiIutJckDZAqB9zuN2wMKayphZM2Ar4OMEYxIRkTxJJoIZQCcz29nMmgO9gYl5ZSYCp0X3TwCeSaR/QEREapRY01DU5j8AeJJw+egId3/bzK4BZrr7ROA+4E9mNodwJtA7qXhERKR6iY4jcPfJwOS8567Iub8SODHJGEREpHaadE5EJOOUCEREMk6JQEQk45QIREQyzkrtak0zWwJ8UM9fb03eqOWMyGK9s1hnyGa9s1hnqHu9O7h7m+o2lFwi2BhmNtPdu6QdR7Flsd5ZrDNks95ZrDM0bL3VNCQiknFKBCIiGZe1RDA87QBSksV6Z7HOkM16Z7HO0ID1zlQfgYiIbChrZwQiIpJHiUBEJOPKMhGY2VFm9p6ZzTGzQdVsb2FmD0Xbp5tZx+JH2bBi1PliM5ttZrPM7O9m1iGNOBtaoXrnlDvBzNzMSv4ywzh1NrNe0d/7bTMbU+wYkxDjPV5hZs+a2WvR+/yYNOJsSGY2wswWm9lbNWw3MxsSvSazzGzfeh3I3cvqRpjy+p/AN4HmwBtA57wy5wHDovu9gYfSjrsIdf4fYLPo/rmlXue49Y7KtQKeB6YBXdKOuwh/607Aa8A20ePt0o67SPUeDpwb3e8MzEs77gao9w+AfYG3ath+DPA4YbXHA4Dp9TlOOZ4RdAXmuPtcd18NPAjkr1HZExgZ3R8PHGZW0osUF6yzuz/r7iuih9MIK8aVujh/a4BrgZuBlcUMLiFx6nwWMNTdlwG4++Iix5iEOPV2YMvo/lZsuCJiyXH356l91caewCgPpgFbm9mOdT1OOSaCtsD8nMcLoueqLePulcByYNuiRJeMOHXOdSbhW0SpK1hvM9sHaO/uk4oZWILi/K13BXY1sxfNbJqZHVW06JITp95XAX3NbAFhHZQLihNaqur6v1+tRBemSUl13+zzr5GNU6aUxK6PmfUFugCHJBpRcdRabzNrAtwB9CtWQEUQ52/djNA89EPCmd8LZranu3+ScGxJilPvPsD97n6bmXUjrH64p7tXJR9eahrks6wczwgWAO1zHrdjw1PEr8qYWTPCaWRtp1+NXZw6Y2bdgcFAD3dfVaTYklSo3q2APYHnzGweoQ11Yol3GMd9f//F3de4+7+A9wiJoZTFqfeZwDgAd38J2JQwMVs5i/W/X0g5JoIZQCcz29nMmhM6gyfmlZkInBbdPwF4xqOelxJVsM5RE8ndhCRQDm3GUKDe7r7c3Vu7e0d370joG+nh7jPTCbdBxHl/TyBcHICZtSY0Fc0tapQNL069/w0cBmBmuxMSwZKiRll8E4FTo6uHDgCWu/t/6rqTsmsacvdKMxsAPEm40mCEu79tZtcAM919InAf4bRxDuFMoHd6EW+8mHW+BdgCeDjqF/+3u/dILegGELPeZSVmnZ8EjjCz2cBa4FJ3X5pe1BsvZr0HAveY2c8JzSP9SvwLHmY2ltDE1zrq+7gS2ATA3YcR+kKOAeYAK4DT63WcEn+dRERkI5Vj05CIiNSBEoGISMYpEYiIZJwSgYhIxikRiIhknBKBSAMxsx7rZsU0s6vM7JK0YxKJo+zGEYikJbqWvezGLkj50xmBSMTM+prZy2b2upndbWZNzexzM7vNzF6N1nFoE5W9MGd9hwej5/qZ2V3V7HfvaPK3WWb2qJltEz3/nJndFB3z/8zs4OLWWCRQIhDhqykJfgoc6O57E0bkngxsDrzq7vsCUwgjOwEGAfu4+17AOQV2Pwq4LCr7Zs4+AJq5e1fgorznRYpGTUMiwWHAfsCMaAqOlsBioAp4KCrzAPBIdH8WMNrMJhDm9qmWmW0FbO3uU6KnRgIP5xRZt79XgI4bXQuRetAZgUhgwEh33zu67ebuV1VTbt2cLD8ChhKSxyvRLLb1sW4W2LXoi5mkRIlAJPg7cIKZbQdgZt+wsK5zE8IMtQAnAVOjdQ7au/uzwC+ArQkT+m3A3ZcDy3La/08hNDGJNBr6BiICuPtsM/sV8FT0Qb8GOB/4AtjDzF4hrGT3U8Lslw9EzT4G3OHun9Sy2ulpwDAz24wwHXS9ZogUSYpmHxWphZl97u7VftsXKRdqGhIRyTidEYiIZJzOCEREMk6JQEQk45QIREQyTolARCTjlAhERDLu/wEQR4C1shY8FQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "eps = np.arange(0,1,0.01)\n",
    "error_rate= np.empty(0)\n",
    "for i in range(len(eps)):\n",
    "    error = 0 \n",
    "    for j in range(len(X_test)):\n",
    "        if p_values[j,y_test[j]] <= eps[i]:\n",
    "            error += 1\n",
    "    error_rate = np.append(error_rate,(error/len(X_test)))\n",
    "    \n",
    "plt.plot(eps,error_rate, color=\"r\")\n",
    "plt.xlabel(\"epsilon\")\n",
    "plt.ylabel(\"% error rate\")\n",
    "plt.title(\"Calibration curve for wine dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an ideal calibaration curve as it is a diagonal from (0,0) to (1,1). The slight deviations from the diaganol can be put down to the size of the dataset meaning that the law of large numbers is not in full effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SVM with cross-confromal prediction on the USPS datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X1 = np.genfromtxt(\"digit_test.txt\", delimiter=\" \", usecols=np.arange(256)+1)\n",
    "X2 = np.genfromtxt(\"digit_train.txt\", delimiter=\" \", usecols=np.arange(256)+1)\n",
    "y1 = np.genfromtxt(\"digit_test.txt\", delimiter=\" \", usecols=0)\n",
    "y2 = np.genfromtxt(\"digit_train.txt\", delimiter=\" \", usecols=0)\n",
    "X = np.concatenate((X1,X2))\n",
    "y = np.concatenate((y1,y2))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1504)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average false p value for 3 fold cross-confromal prediction is: 0.0038830642377040317\n",
      "The average false p value for 5 fold cross-confromal prediction is: 0.004020945624362554\n",
      "The average false p value for 10 fold cross-confromal prediction is: 0.003713387104486651\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "folds = [3,5,10]\n",
    "average_false_p_value = np.empty(0)\n",
    "param_grid ={'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "for f in range(len(folds)):\n",
    "    kf = KFold(shuffle=True, random_state=1504, n_splits=folds[f])\n",
    "    alpha = np.empty(0)\n",
    "    for rest_index, fold_index in kf.split(X_train):\n",
    "        X_rest, X_fold, y_rest, y_fold = X_train[rest_index], X_train[fold_index], y_train[rest_index], y_train[fold_index]\n",
    "        grid = GridSearchCV(SVC(), param_grid=param_grid, cv=5, iid='True', n_jobs = -1)\n",
    "        grid.fit(X_rest, y_rest)\n",
    "        all_calibration_conformity_scores = grid.decision_function((X_fold))\n",
    "        calibration_conformity_scores = np.empty(len(all_calibration_conformity_scores))\n",
    "        for i in range(len(all_calibration_conformity_scores)):\n",
    "            calibration_conformity_scores[i] = all_calibration_conformity_scores[i,int(y_fold[i])]\n",
    "        X_test_conformity_scores = grid.decision_function(X_test)\n",
    "        for i in range(len(X_test)):\n",
    "            for j in range(10):\n",
    "                rank = 0\n",
    "                for k in range(len(X_fold)):\n",
    "                    if X_test_conformity_scores[i,j] >= calibration_conformity_scores[k]:\n",
    "                        rank += 1\n",
    "                alpha = np.append(alpha,int(rank))\n",
    "\n",
    "    alpha = alpha.reshape(folds[f],len(X_test),10)\n",
    "    p_values = (sum(alpha)+1)/((len(X_fold)*folds[f])+1)\n",
    "    false_p_value = 0\n",
    "    for a in range (len(p_values)):\n",
    "        false_p_value += np.sum(p_values[a]) - p_values[a,int(y_test[a])]\n",
    "    average_false_p_value = np.append(average_false_p_value, (false_p_value/(p_values.shape[0]*(p_values.shape[1]-1))))\n",
    "print(\"The average false p value for 3 fold cross-confromal prediction is:\", average_false_p_value[0])\n",
    "print(\"The average false p value for 5 fold cross-confromal prediction is:\", average_false_p_value[1])\n",
    "print(\"The average false p value for 10 fold cross-confromal prediction is:\", average_false_p_value[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data isn't normalized in the cross confromal prediction as it is clear that normalization is not needed on the USPS dataset. Here the 10 fold cross-conformal prediction gives the lowest average false p value. The 10 fold cross-conformal prediction takes quite a long time to implement and therefore slightly lacks in computaional efficiency. This however is not a huge issue and the 10 fold cross-conformal predction seems the optimal option. Chosing any more folds may result in too much of as loss in compuataional efficiency considering the improvements it will make on the test error rate will be very minor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "eps = np.arange(0,1,0.01)\n",
    "error_rate= np.empty(0)\n",
    "for i in range(len(eps)):\n",
    "    error = 0 \n",
    "    for j in range(len(X_test)):\n",
    "        if p_values[j,int(y_test[j])] <= eps[i]:\n",
    "            error += 1\n",
    "    error_rate = np.append(error_rate,(error/len(X_test)))\n",
    "    \n",
    "plt.plot(eps,error_rate, color=\"b\")\n",
    "plt.xlabel(\"epsilon\")\n",
    "plt.ylabel(\"% error rate\")\n",
    "plt.title(\"Calibration curve for USPS dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the calibration curve is much more true to the diagonal line. This can be down to the USPS dataset being so large. Due to this the error rate closes in on the true value of epsilon, this is due to the law of large numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All results rounded to 3 significant figures\n",
    "\n",
    "* non normalized wine dataset generalization accuracy of SVM with the default values of the parameter: 0.436\n",
    "* non normalized wine dataset test error rate for the SVM with the default values of the parameters: 0.622\n",
    "* wine dataset test error rate of GridSearchCV for MinMaxScaler: 0.0222\n",
    "* wine dataset test error rate of GridSearchCV for StandardScaler: 0.0222\n",
    "* wine dataset test error rate of GridSearchCV for no scaler: 0.178\n",
    "* wine dataset average false p value for 10 fold cross-conformal prediction: 0.00865\n",
    "* non normalized USPS dataset generalization accuracy of SVM with the default values of the parameter: 0.969\n",
    "* non normalized USPS dataset test error rate for the SVM with the default values of the parameters: 0.0348\n",
    "* USPS dataset test error rate of GridSearchCV for Normalizer: 0.0280\n",
    "* USPS dataset test error rate of GridSearchCV for MinMaxScaler: 0.0293\n",
    "* USPS dataset test error rate of GridSearchCV for no scaler: 0.0262\n",
    "* USPS dataset average false p value for 10 fold cross-conformal prediction: 0.00371"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
